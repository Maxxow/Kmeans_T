
import os
import json
from django.shortcuts import render
from django.http import JsonResponse
from django.conf import settings

def tumor_view(request):
    return render(request, 'api/tumor_detect.html')

def index(request):
    # Static Data Loading (Low Memory)
    # We load the pre-calculated stats from the JSON file generated by the script
    json_path = os.path.join(settings.BASE_DIR, 'api/static/api/assets/clusters_data.json')
    
    # Get user input for simulation (default to 6)
    user_n_clusters = request.GET.get('n_clusters', 6)
    
    context = {}
    if os.path.exists(json_path):
        with open(json_path, 'r') as f:
            data = json.load(f)
            # Use user input for the UI label to simulate "dynamic" behavior
            context['n_clusters'] = user_n_clusters
            
            # Calculate percentages
            counts_dict = data.get('counts', {})
            total = sum(counts_dict.values())
            cluster_stats = []
            for cid, count in counts_dict.items():
                pct = (count / total * 100) if total > 0 else 0
                cluster_stats.append({
                    'id': cid,
                    'count': count,
                    'pct': round(pct, 2)
                })
            # Sort numerically if possible
            cluster_stats.sort(key=lambda x: int(x['id']) if x['id'].isdigit() else x['id'])
            
            context['cluster_stats'] = cluster_stats
            
    return render(request, 'api/index.html', context)

def clusters_data(request):
    json_path = os.path.join(settings.BASE_DIR, 'api/static/api/assets/clusters_data.json')
    if os.path.exists(json_path):
        with open(json_path, 'r') as f:
            data = json.load(f)
        return JsonResponse(data)
    return JsonResponse({'error': 'Data not found'}, status=404)

# Tumor Model Integration
import joblib
import numpy as np
from django.views.decorators.csrf import csrf_exempt

# Global model variable to load once
TUMOR_MODEL = None
MODEL_PATH = os.path.join(settings.BASE_DIR, 'tumor_model.joblib')

def load_tumor_model():
    global TUMOR_MODEL
    if TUMOR_MODEL is None and os.path.exists(MODEL_PATH):
        try:
            TUMOR_MODEL = joblib.load(MODEL_PATH)
            print("Tumor model loaded successfully.")
        except Exception as e:
            print(f"Error loading tumor model: {e}")
    return TUMOR_MODEL

@csrf_exempt
def predict_tumor(request):
    if request.method != 'POST':
        return JsonResponse({'error': 'Solo método POST permitido'}, status=405)
    
    if 'image' not in request.FILES:
        return JsonResponse({'error': 'No se proporcionó imagen'}, status=400)
    
    model = load_tumor_model()
        
    try:
        import io
        import base64
        from PIL import Image, ImageOps, ImageEnhance
        
        image_file = request.FILES['image']
        img = Image.open(image_file)
        
        # 1. Prediction (Resize to 64x64 for model)
        img_gray = img.convert('L')
        img_resized = img_gray.resize((64, 64))
        img_arr = np.array(img_resized).flatten().reshape(1, -1)
        
        prediction = 0
        if model:
            prediction = model.predict(img_arr)[0]
        
        # Translate Result
        result_text = "Tumor Detectado" if prediction == 1 else "No se detectó Tumor"
        
        if prediction == 1:
            # 2. Advanced Visualization Mask (Heuristic - RED for Tumor)
            # Only generate mask if tumor is detected
            
            # Convert to grayscale for initial processing
            display_img = img.resize((500, 500))
            gray_display = display_img.convert('L')
            
            # Enhance Contrast to bring out potential features
            enhancer = ImageEnhance.Contrast(gray_display)
            contrasted = enhancer.enhance(2.0)
            
            # Create Red Mask
            mask = Image.new('RGBA', display_img.size, (0, 0, 0, 0))
            pixels = mask.load()
            src_pixels = contrasted.load()
            
            width, height = display_img.size
            for x in range(width):
                for y in range(height):
                    val = src_pixels[x, y]
                    # Thresholding Logic
                    if val > 120:
                        # Normalize intensity 120-255 -> 0-1
                        norm = (val - 120) / 135.0
                        
                        # Color Mapping (Red Overlay)
                        r = 255
                        g = 0
                        b = 0
                        # Alpha between 100 (transparent) and 200 (more opaque)
                        alpha = int(100 + (100 * norm)) 
                        
                        pixels[x, y] = (r, g, b, alpha)
    
            buffer = io.BytesIO()
            mask.save(buffer, format="PNG")
            mask_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        else:
            mask_base64 = None

        return JsonResponse({
            'prediction_text': result_text, 
            'class_id': int(prediction),
            'mask_image': mask_base64
        })
        
    except Exception as e:
        return JsonResponse({'error': str(e), 'prediction_text': 'Error', 'class_id': 0}, status=500)

# Emotion Detection (Mock/Placeholder)
def emotion_view(request):
    return render(request, 'api/emotion_detect.html')

@csrf_exempt
def predict_emotion(request):
    if request.method != 'POST':
        return JsonResponse({'error': 'POST only'}, status=405)
    
    # Mock Logic since TensorFlow is missing
    # Translated Emotions
    import random
    emotions = [
        {"emotion": "Felicidad"},
        {"emotion": "Neutral"},
        {"emotion": "Tristeza"},
        {"emotion": "Sorpresa"},
        {"emotion": "Ira"},
        {"emotion": "Miedo"}
    ]
    
    selected = random.choice(emotions)
    
    import time
    time.sleep(1)
    
    return JsonResponse(selected)
